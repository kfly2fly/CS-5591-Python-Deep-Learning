{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WE-sentiment_analysis-usecase.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Remember From the Top Menu Click on Runtime -> Change Runtime type -> then Choose GPU to accelerate the learning.**"
      ],
      "metadata": {
        "id": "B0zRN7Sm9Ab1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCGsF9irW4Cz"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "jtk7nwZ4qgL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kn23PUg9WmN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNaC3jEBW9dw"
      },
      "source": [
        "df = pd.read_csv('/imdb_master.csv',encoding='latin-1')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df['review'].values\n",
        "y = df['label'].values"
      ],
      "metadata": {
        "id": "5aX6mS_1wOpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(unique, counts) = np.unique(y, return_counts=True)\n",
        "\n",
        "frequencies = np.asarray((unique, counts)).T\n",
        "\n",
        "print(frequencies)"
      ],
      "metadata": {
        "id": "rnG-6A6VpsN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df6hooweXBJo"
      },
      "source": [
        "tokenizing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSUceLgkW-wI"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR78DrA6XD48"
      },
      "source": [
        "getting the vocabulary of data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms each text in texts to a sequence of integers.\n",
        "# Only top num_words-1 most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.\n",
        "\n",
        "# Transforms each text in texts to a sequence of integers. \n",
        "# So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
        "X = tokenizer.texts_to_sequences(sentences)"
      ],
      "metadata": {
        "id": "cqW0hpE5beji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nLen() of X:', len(X))\n",
        "print('\\n', X[:2])"
      ],
      "metadata": {
        "id": "s_Hk__8Jbk0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(X) # Pads sequences to the same length.\n",
        "print('X.shape = ', X.shape)"
      ],
      "metadata": {
        "id": "T885TTUkbpGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuJJ6l52XHTw"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "W7ig6dd14w8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "R8u2v7cLXNQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcyQwlRNXI6V"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(300,input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "PP5EQL0BYSzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGpcm3BIXNmL"
      },
      "source": [
        "history=model.fit(X_train,y_train, epochs=50, verbose=True, validation_data=(X_test,y_test), batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}